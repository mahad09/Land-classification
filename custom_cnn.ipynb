{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-adapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from keras.layers import Activation, Dense, Dropout, Flatten\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras.applications import VGG16, ResNet50\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Flatten, Activation, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.optimizers import Adam\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import pdb\n",
    "from skimage.io import imread, imsave\n",
    "from tqdm import tqdm\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promising-reviewer",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_DATA_DIR = 'dataset_1/train/'\n",
    "VALIDATION_DATA_DIR = 'dataset_1/validate/'\n",
    "\n",
    "IMG_HEIGHT = 256\n",
    "IMG_WIDTH = 256\n",
    "INPUT_SHAPE = (256, 256, 3)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 200\n",
    "NUM_OF_CLASSES = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspected-hardware",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generators():\n",
    "  print('defining generators of training and validation sets...')\n",
    "  train_datagen = ImageDataGenerator(\n",
    "    rotation_range = 40,                  \n",
    "    width_shift_range = 0.2,                  \n",
    "    height_shift_range = 0.2,                  \n",
    "    rescale = 1./255,                  \n",
    "    shear_range = 0.2,                  \n",
    "    zoom_range = 0.2,                     \n",
    "    horizontal_flip = True\n",
    "    )\n",
    "\n",
    "  validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "  train_data = train_datagen.flow_from_directory(\n",
    "    TRAINING_DATA_DIR, target_size=(IMG_WIDTH, IMG_HEIGHT), batch_size=BATCH_SIZE, class_mode='categorical')\n",
    "\n",
    "  validation_data = validation_datagen.flow_from_directory(\n",
    "    VALIDATION_DATA_DIR, target_size=(IMG_WIDTH, IMG_HEIGHT), batch_size=BATCH_SIZE, class_mode='categorical')\n",
    "\n",
    "  return train_data, validation_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-therapy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_cnn():\n",
    "  model = Sequential()\n",
    "  model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(IMG_WIDTH, IMG_HEIGHT, 3),\n",
    "                 data_format='channels_last'))\n",
    "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "  model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "  model.add(Dropout(0.25))\n",
    "  model.add(Flatten())\n",
    "  model.add(Dense(128, activation='relu'))\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Dense(21, activation='softmax'))\n",
    "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-cedar",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(model, train_generator, validation_generator):\n",
    "  history = model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch = train_generator.samples // BATCH_SIZE,\n",
    "      validation_data = validation_generator, \n",
    "      validation_steps = validation_generator.samples // BATCH_SIZE,\n",
    "      epochs = EPOCHS,\n",
    "      workers=4)\n",
    "\n",
    "  model.save('land_classifier.h5')\n",
    "\n",
    "  return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-clock",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cf_matrix(predicted_labels, correct_labels):\n",
    "  cf_matrix = confusion_matrix(predicted_labels, correct_labels)\n",
    "  fig, ax = plt.subplots(figsize=(8, 6))\n",
    "  sns.heatmap(cf_matrix, cmap=\"YlGnBu\", annot=True, linewidths=.5, ax=ax, fmt=\".0f\")\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "def cls_report(predicted_labels, correct_labels):\n",
    "  print(classification_report(predicted_labels, correct_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharp-dealer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(test_data):\n",
    "  trained_model = keras.models.load_model('models/land_classifier_vgg16.h5')\n",
    "  overall_result = trained_model.evaluate(test_data)\n",
    "  print(dict(zip(trained_model.metrics_names, overall_result)))\n",
    "\n",
    "  y_pred = []  # store predicted labels\n",
    "  y_true = []  # store true labels\n",
    "\n",
    "  testing = []\n",
    "  counter = 0\n",
    "  actual = []\n",
    "  for folder in tqdm(os.listdir(VALIDATION_DATA_DIR)):\n",
    "    for image in os.listdir(VALIDATION_DATA_DIR + folder + '/'):\n",
    "      img = cv2.imread(VALIDATION_DATA_DIR + folder + '/' + image)\n",
    "      img = cv2.resize(img, (256, 256))\n",
    "      img = np.array(img)\n",
    "      img = img.reshape(1, 256, 256, 3)\n",
    "      # img = img.flatten()\n",
    "      img *= 255\n",
    "      predict = trained_model.predict(img)\n",
    "      # print(counter, 'actual: ', validation_generator.class_indices[folder],'  ', 'predicted: ', np.argmax(predict, axis=1))\n",
    "      testing.append(np.argmax(predict))\n",
    "      actual.append(test_data.class_indices[folder])\n",
    "      counter += 1\n",
    "    print(counter)\n",
    "\n",
    "  cf_matrix(actual, testing)\n",
    "  cls_report(actual, testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-output",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy(history):\n",
    "    plt.title(\"Accuracy Graph\")\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train_accuracy', 'validation_accuracy'], loc='best')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_loss(history):\n",
    "    plt.title(\"Loss Graph\")\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train_loss', 'validation_loss'], loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "backed-electron",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, validation_data = data_generators()\n",
    "compiled_model = custom_cnn()\n",
    "history, trained_model = model_training(compiled_model, train_data, validation_data)\n",
    "plot_accuracy(history)\n",
    "plot_loss(history)\n",
    "model_evaluation(validation_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
